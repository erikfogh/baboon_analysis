{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../scripts/notebook_settings.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data_samples = pd.read_table(\"../data/metadata_with_x_missing.txt\", sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "zarr_dir = \"/faststorage/project/baboondiversity/data/PG_panu3_zarr_01_03_2021/callset.zarr/chr7\"\n",
    "#Opening the zarr data\n",
    "callset = zarr.open_group(zarr_dir, mode=\"r\")\n",
    "gt = allel.GenotypeArray(callset[\"calldata/GT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ld(gn, title):\n",
    "    m = allel.rogers_huff_r(gn) ** 2\n",
    "    ax = allel.plot_pairwise_ld(m)\n",
    "    ax.set_title(title)\n",
    "\n",
    "def ld_prune(gn, size, step, threshold=.1, n_iter=1):\n",
    "    for i in range(n_iter):\n",
    "        loc_unlinked = allel.locate_unlinked(gn, size=size, step=step, threshold=threshold)\n",
    "        n = np.count_nonzero(loc_unlinked)\n",
    "        n_remove = gn.shape[0] - n\n",
    "        print('iteration', i+1, 'retaining', n, 'removing', n_remove, 'variants')\n",
    "        gn = gn.compress(loc_unlinked, axis=0)\n",
    "    return gn\n",
    "\n",
    "def offset_legend(fig):\n",
    "    ax = fig.add_subplot(111)\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    lgd = ax.legend(handles, labels, loc='best', bbox_to_anchor=(1,1))\n",
    "    return lgd\n",
    "\n",
    "def pruning_and_pca(gt, IDs, subsampling_n, size, n_iter):\n",
    "    print(\"Investigating {} individuals\".format(len(IDs)))\n",
    "    gt = gt.take(IDs, axis=1)\n",
    "    ac = gt.count_alleles()[:] #Allele counts for each pos\n",
    "    flt = (ac.max_allele() == 1) & (ac[:, :2].min(axis=1) > 1) #Filtering for biallelic \n",
    "    #and at least two individuals in the alt state\n",
    "    gf = gt.compress(flt, axis=0) #Applying filter\n",
    "    gn = gf.to_n_alt() #Transform genotype to number of non-ref alleles\n",
    "    if subsampling_n > len(gn):\n",
    "        subsampling_n = len(gn)-1\n",
    "    vidx = np.random.choice(gn.shape[0], subsampling_n, replace=False) #Random subsampling\n",
    "    vidx.sort()\n",
    "    gnr = gn.take(vidx, axis=0) #Applying the random subsample\n",
    "    gnu = ld_prune(gnr, size=size, step=200, threshold=.1, n_iter=n_iter) #Pruning based on LD\n",
    "    if len(gnu) > 150000:\n",
    "        print(\"Too large dataset for pca\")\n",
    "        return \"Too large dataset for pca\"\n",
    "    gnu = gnu[:] #Taking it out of chunked storage\n",
    "    coords1, model1 = allel.pca(gnu, n_components=10, scaler='patterson') #Running the pca\n",
    "    #The plotting solution in the example is inflexible, so I will try to make it through seaborn.\n",
    "    pca_df = pd.DataFrame()\n",
    "    c_transposed = coords1.transpose()\n",
    "    for i in range(len(c_transposed)):\n",
    "        pc = \"pc{}\".format(i+1)\n",
    "        pca_df[pc] = c_transposed[i]\n",
    "    pca_df[\"callset_index\"] = IDs\n",
    "    pca_df_meta = pd.merge(pca_df, meta_data_samples)\n",
    "    fig, ax = plt.subplots()\n",
    "    sns.despine(ax=ax)\n",
    "    x = np.arange(10)\n",
    "    y = model1.explained_variance_ratio_ * 100\n",
    "    ax.bar(x+.6, y, width=.8)\n",
    "    ax.set_xticks(x+1)\n",
    "    ax.set_xlim(0, 11)\n",
    "    ax.set_xlabel('component')\n",
    "    ax.set_ylabel('% variance explained')\n",
    "    return pca_df_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Investigating 217 individuals\n"
     ]
    }
   ],
   "source": [
    "IDs = meta_data_samples.callset_index.values\n",
    "pca_df = pruning_and_pca(gt, IDs, 2000000, 500, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "scatter_sns = sns.scatterplot(data = pca_df, x=\"pc1\", y=\"pc2\", hue=\"C_origin\", style=\"Sex\")\n",
    "fig_males = scatter_sns.get_figure()\n",
    "lgd = offset_legend(fig_males)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "scatter_sns = sns.scatterplot(data = pca_df, x=\"pc3\", y=\"pc4\", hue=\"C_origin\", style=\"Sex\")\n",
    "fig_males = scatter_sns.get_figure()\n",
    "lgd = offset_legend(fig_males)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "scatter_sns = sns.scatterplot(data = pca_df, x=\"pc5\", y=\"pc6\", hue=\"C_origin\", style=\"Sex\")\n",
    "fig_males = scatter_sns.get_figure()\n",
    "lgd = offset_legend(fig_males)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "pca_df_subset = pca_df.loc[pca_df.Species==\"anubis\"]\n",
    "scatter_sns = sns.scatterplot(data = pca_df_subset, x=\"pc5\", y=\"pc6\", hue=\"Origin\", style=\"Sex\")\n",
    "fig_males = scatter_sns.get_figure()\n",
    "lgd = offset_legend(fig_males)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
